<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>

   <!-- Standard site meta information -->
   <meta http-equiv="content-type" content="text/html; charset=utf-8" />
   <title>Bayesian Updating as Regularised Optimisation ← Inductio Ex Machina ← Mark Reid</title>
   <meta name="author" content="Mark Reid" />

   <link rel="openid.server" href="http://www.myopenid.com/server" />
   <link rel="openid.delegate" href="http://mark.reid.name" />

   <link rel="start" href="../" />

   <!-- syntax highlighting CSS -->
   <link rel="stylesheet" href="../css/syntax.css" type="text/css" />

   <!-- Homepage CSS -->
   <link rel="stylesheet" href="../css/screen.css" type="text/css" media="all" />
   <link rel="stylesheet" href="../css/print.css" type="text/css" media="print" />
   <link rel="stylesheet" href="../css/widgets.css" type="text/css" media="all" />
   <link rel="stylesheet" href="../css/amjr.css" type="text/css" media="all" />

 	<meta name="twitter:card" content="summary">
    <meta name="twitter:creator" content="@mdreid">
    <meta name="twitter:site" content="@mdreid">
    <meta name="twitter:title" content="Bayesian Updating as Regularised Optimisation">
    <meta name="twitter:description" content="A brief description and discussion of Zhu et al.'s RegBayes framework for generalising Bayesian updating.">

<!-- MathJax configuration and loading -->
<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
		extensions: ["tex2jax.js"],
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["\\(","\\)"] ],
			displayMath: [ ["\\[","\\]"] ],
			processEscapes: true
		},
		TeX: { equationNumbers: { autoNumber: "AMS" } },
		"HTML-CSS": { availableFonts: ["TeX"] }
	});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script>

</head>

<body id="Blog">

<div id="site">
  <div id="header">
<h1>
	<a href="../blog/" title="A machine learning blog">Inductio ex Machina</a>
	<span class="byline">← <a href="../">Mark Reid</a></span>
</h1>
<ul class="nav">
  <li><a class="home" href="../blog/">Home</a></li>
  <li><a class="info" href="../blog/info.html">Info</a></li>
  <li><a class="past" href="../blog/past.html">Past</a></li>
  <li><a class="kith" href="../blog/kith.html">Kith</a></li>
</ul>
</div>

<div id="page">

<h1 class="emphnext">Bayesian Updating as Regularised Optimisation</h1>

<p>I recently attended a workshop at <a href="http://www.tsinghua.edu.cn/publish/csen/">Tsinghua University</a> in Beijing on social networking and machine learning. One of the more machine learning focused talks by <a href="http://bigml.cs.tsinghua.edu.cn/~jun">Jun Zhu</a> caught my attention with a simple but surprising generalisation of Bayesian updating which he and his co-authors call “Regularized Bayesian Inference” or <a href="http://bigml.cs.tsinghua.edu.cn/~jun/research.shtml">RegBayes</a>.</p>
<p>The core idea is very simple: express classical Bayesian updating as an optimisation problem (see below) and then add constraints and regularisers to the posterior distribution. The advantage to this approach is that it affords an extra way to encode domain knowledge about problems.</p>
<p>The closest thing I’d seen to something like output regularisation was in a 2007 JMLR paper, <em><a href="http://jmlr.csail.mit.edu/papers/v8/rifkin07a.html">Value Regularization and Fenchel Duality</a></em> by Rifkin &amp; Lippert.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> However, RegBayes specifically starts with Bayesian updating and regularises distributions instead of just values.</p>
<p>I really like seeing new takes on old ideas, so I thought I’d work through the representation of updating as optimisation. The derivation below is an expansion of what is worked through in Section 3 of a recent paper by Zhu, Chen, and Xing titled <em><a href="http://jmlr.org/papers/v15/zhu14b.html">Bayesian Inference with Posterior Regularization and Applications to Infinite Latent SVMs</a></em>. Interested readers can also find an extended discussion, applications and connections with earlier work there.</p>
<h2 id="bayesian-updating-as-divergence-optimisation">Bayesian Updating as Divergence Optimisation</h2>
<p>We’ll start by letting <span class="math">\({\mathcal{M}}\)</span> be a set of models and <span class="math">\(\Delta_{\mathcal{M}}\)</span> the set of distributions over <span class="math">\({\mathcal{M}}\)</span>. If <span class="math">\(\pi(M)\)</span> denotes the prior probability of a model <span class="math">\(M \in {\mathcal{M}}\)</span> and <span class="math">\(p(D|M)\)</span> denote the data likelihood for <span class="math">\(D\)</span> given <span class="math">\(M\)</span> then, as everyone knows, Bayes’ rule states that the posterior <span class="math">\(p(M|D)\)</span> can be computed via <span class="math">\[
	p(M|D) = \frac{\pi(M) p(D|M)}{p(D)}
\]</span> where <span class="math">\(p(D)\)</span> is the marginal distribution over the data.</p>
<p>Now, it is well known that the <a href="http://en.wikipedia.org/wiki/Kullback–Leibler_divergence">KL divergence</a> from a distribution <span class="math">\(p\)</span> to a distribution <span class="math">\(q\)</span> — denoted <span class="math">\(KL(q\|p)\)</span> — is minimised and equal to zero when, and only when, <span class="math">\(q = p\)</span> (almost everywhere). This means that if we had some arbitrary distribution <span class="math">\(q(M)\)</span> over models and wanted to ensure it was equal to the posterior distribution <span class="math">\(p(M|D)\)</span> obtained by updating a prior <span class="math">\(\pi\)</span> with data <span class="math">\(D\)</span> we could do so in a round-about sort of way by solving the following optimisation problem: <span class="math">\[ \begin{equation} \inf_{q(M)}\ KL(q(M)\|p(M|D))\quad \text{s.t.}\quad  q \in \Delta_{\mathcal{M}}.\label{eq:kl} \end{equation}
\]</span> Although this is not a particularly interesting optimisation problem, things get a little more interesting if we expand the KL divergence term. Letting <span class="math">\(p_L = p(D|M)\)</span> denote the data likelihood and <span class="math">\(p_D = p(D)\)</span> the data marginal we see that <span class="math">\[ 
	KL\left(q\|\frac{\pi p_L}{p_D}\right) 
	= {\mathbb{E}}_q\left[\ln\frac{q}{\pi p_L / p_D}\right]
	= {\mathbb{E}}_q\left[\ln \frac{q}{\pi} - \ln p_L + \ln p_D\right]
\]</span> and so the <span class="math">\(KL\)</span> term in the optimisation problem above can be written as <span class="math">\[ \begin{align*} KL(q(M)\|p(M|D)) &amp;= KL(q(M)\|\pi(M) p(D|M) / p(D)) \\ &amp;= KL(q(M)\|\pi(M)) - {\mathbb{E}}_{M\sim q}\left[ \ln p(D|M) \right] + \ln p(D) \end{align*} \]</span> since <span class="math">\(p(D)\)</span> does not depend on <span class="math">\(M\)</span>. The <span class="math">\(\ln p(D)\)</span> term is also irrelevant for the optimisation in \eqref{eq:kl} so we can now express that problem as <span class="math">\[
	\inf_{q(M)}\ 
		\underbrace{KL(q(M)\|\pi(M))}_{\text{closeness to prior}} 
		+ 
		\underbrace{{\mathbb{E}}_{M\sim q}\left[ -\ln p(D|M) \right]}_{\text{fit to data}}
		\quad 
		\text{s.t.}\quad  q \in \Delta_{\mathcal{M}}.
\]</span></p>
<p>The nice thing about expressing the posterior as the solution of the above problem is that we can see the Bayesian updating as a trade-off between staying close to the prior and fitting the data. The KL term keeps the posterior close to the prior while the other term measures the expected log loss of the model’s ability to predict the data.</p>
<h2 id="adding-in-regularisation">Adding in Regularisation</h2>
<p>The interesting insight Jun and his co-authors had was that the above optimisation problem can be tweaked slightly by adding either extra constraints to where <span class="math">\(q\)</span> can lie in <span class="math">\(\Delta_{\mathcal{M}}\)</span> or by adding an additional regularisation term <span class="math">\(U(q)\)</span> which may or may not depend on the data. In its most general setting, updating a prior <span class="math">\(\pi\)</span> given data <span class="math">\(D\)</span> can be written as <span class="math">\[
	\inf_{q(M)}\ KL(q(M)\|\pi(M)) + {\mathbb{E}}_q\left[-\ln p(D|M)\right] + U(q(M))
	\quad
	\text{s.t.}\quad q\in{\mathcal{Q}}\]</span> where <span class="math">\(U\)</span> is a regulariser and <span class="math">\({\mathcal{Q}}\subseteq \Delta_{\mathcal{M}}\)</span> are the allowable distributions. The distribution <span class="math">\(q(M)\)</span> solving the above problem is called the “post-data distribution” to distinguish it from the traditional posterior distribution.</p>
<h2 id="questions">Questions</h2>
<p>One question that sprung to mind when I first saw this was whether this setting is strictly more general than normal Bayesian updating. The regularisation and constraints control which post-data distribution is selected but could such a post-data distribution be achieved as the posterior of normal Bayesian updating for a different prior?</p>
<p>It turns out the answer is “no”. Since the regulariser <span class="math">\(U\)</span> can depend on the data, it is possible to create updating schemes that are not doing strict Bayesian updating. I’m not sure whether the same holds if <span class="math">\(U\)</span> and <span class="math">\({\mathcal{Q}}\)</span> are not allowed to depend on the data but I suspect RegBayes would still be more general.</p>
<p>Some other questions that came up in my discussions with Jun included:</p>
<ul>
<li>What sort of convergence and consistency guarantees can be given for this scheme?</li>
<li>Could there be connections between RegBayes and PAC-Bayesian theory?</li>
<li>Could KL divergence and log loss be replaced by other <a href="http://jmlr.csail.mit.edu/papers/v12/reid11a.html">loss/divergence pairs</a>?</li>
<li>Do some choices of regulariser yield updates for non-standard uncertainty calculi?</li>
</ul>
<p>I haven’t yet spent much time thinking about these but I find this approach a fascinating way to couch the problem of managing uncertainty.</p>
<h2 id="updates">Updates</h2>
<ul>
<li>2014–11–24: Updated links to Jun Zhu’s new <a href="http://bigml.cs.tsinghua.edu.cn/~jun">home page</a>, <a href="http://bigml.cs.tsinghua.edu.cn/~jun/research.shtml">research page</a>, and the <a href="http://jmlr.org/papers/v15/zhu14b.html">JMLR version</a> of the RegBayes paper (the <a href="http://arxiv.org/abs/1210.1766v3">arxiv</a> version has also been updated).</li>
</ul>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>In <a href="http://jmlr.org/papers/v15/zhu14b.html">their paper</a>, Jun Zhu et al. point out a number of other, earlier works that inspired RegBayes but I had either not seen them or made the connection to Bayesian updating before.<a href="#fnref1">↩</a></p></li>
</ol>
</div>


<address class="signature">
	<a class="author" href="http://mark.reid.name">Mark Reid</a>
  <span class="date">May 14, 2013</span>
  <span class="location">Canberra, Australia</span>
</address>

</div>
<address id="feed" class="quiet right">Subscribe: <a href="../blog/atom.xml" title="Subscribe to Atom feed"><em>Atom Feed</em></a></address>


<!-- Disqus Comments -->
<div id="disqus_thread"></div>

<!-- Enable Disqus comments -->
<script type="text/javascript">
        var disqus_iframe_css = "http://mark.reid.name/css/screen.css";
        var disqus_title = "Bayesian Updating as Regularised Optimisation";
        var disqus_message = "A brief description and discussion of Zhu et al.'s RegBayes framework for generalising Bayesian updating.";
</script>
<script type="text/javascript" src="http://disqus.com/forums/markreid/embed.js"></script>

<noscript>
    <a href="http://markreid.disqus.com/?url=ref">View the discussion thread.</a>
</noscript>




    <!-- Footer with copyright and contact information -->
  <div id="footer">
	<address>
		<span class="copyright">
			Content &amp; Design by 
			<a href="../info/site.html">Mark Reid</a>
			<br />
			(<a rel="licence" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Some rights reserved</a>)			
		</span>
		<span class="engine">
			Powered by 
			<a href="http://jaspervdj.be/hakyll/" title="A static, minimalist, Haskell-powered CMS">Hakyll</a>
		</span>
	</address>
  </div>

</div>


<!-- Google Analytics script -->
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-1051817-4");
pageTracker._trackPageview();
</script>
<!--[if IE 6]>
<script type="text/javascript"> 
	/*Load jQuery if not already loaded*/ if(typeof jQuery == 'undefined'){ document.write("<script type=\"text/javascript\"   src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js\"></"+"script>"); var __noconflict = true; } 
	var IE6UPDATE_OPTIONS = {
		icons_path: "http://static.ie6update.com/hosted/ie6update/images/"
	}
</script>
<script type="text/javascript" src="http://static.ie6update.com/hosted/ie6update/ie6update.js"></script>
<![endif]-->


</body>
</html>



